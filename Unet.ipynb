{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the U-Net architecture for binary segmentation\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder (downsampling path)\n",
    "        self.enc_conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.enc_conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.enc_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.enc_conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.enc_conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.enc_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.enc_conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.enc_conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.enc_pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.enc_conv7 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.enc_conv8 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.enc_pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck_conv1 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
    "        self.bottleneck_conv2 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1)\n",
    "\n",
    "        # Decoder (upsampling path)\n",
    "        self.dec_upsample1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.dec_conv1 = nn.Conv2d(1024 + 512, 512, kernel_size=3, padding=1)\n",
    "        self.dec_conv2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.dec_upsample2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.dec_conv3 = nn.Conv2d(512 + 256, 256, kernel_size=3, padding=1)\n",
    "        self.dec_conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.dec_upsample3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.dec_conv5 = nn.Conv2d(256 + 128, 128, kernel_size=3, padding=1)\n",
    "        self.dec_conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.dec_upsample4 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.dec_conv7 = nn.Conv2d(128 + 64, 64, kernel_size=3, padding=1)\n",
    "        self.dec_conv8 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "          # Output\n",
    "        self.output_conv = nn.Conv2d(64, 1, kernel_size=1)  # 1x1 convolution for binary segmentation\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder (downsampling path)\n",
    "        enc1 = nn.ReLU()(self.enc_conv1(x))\n",
    "        enc2 = nn.ReLU()(self.enc_conv2(enc1))\n",
    "        enc2_pool = self.enc_pool1(enc2)\n",
    "\n",
    "        enc3 = nn.ReLU()(self.enc_conv3(enc2_pool))\n",
    "        enc4 = nn.ReLU()(self.enc_conv4(enc3))\n",
    "        enc4_pool = self.enc_pool2(enc4)\n",
    "\n",
    "        enc5 = nn.ReLU()(self.enc_conv5(enc4_pool))\n",
    "        enc6 = nn.ReLU()(self.enc_conv6(enc5))\n",
    "        enc6_pool = self.enc_pool3(enc6)\n",
    "\n",
    "        enc7 = nn.ReLU()(self.enc_conv7(enc6_pool))\n",
    "        enc8 = nn.ReLU()(self.enc_conv8(enc7))\n",
    "        enc8_pool = self.enc_pool4(enc8)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = nn.ReLU()(self.bottleneck_conv1(enc8_pool))\n",
    "        bottleneck = nn.ReLU()(self.bottleneck_conv2(bottleneck))\n",
    "\n",
    "        # Decoder (upsampling path)\n",
    "        dec1 = self.dec_upsample1(bottleneck)\n",
    "        dec1 = torch.cat([dec1, enc8], dim=1)\n",
    "        dec1 = nn.ReLU()(self.dec_conv1(dec1))\n",
    "        dec1 = nn.ReLU()(self.dec_conv2(dec1))\n",
    "\n",
    "        dec2 = self.dec_upsample2(dec1)\n",
    "        dec2 = torch.cat([dec2, enc6], dim=1)\n",
    "        dec2 = nn.ReLU()(self.dec_conv3(dec2))\n",
    "        dec2 = nn.ReLU()(self.dec_conv4(dec2))\n",
    "\n",
    "        dec3 = self.dec_upsample3(dec2)\n",
    "        dec3 = torch.cat([dec3, enc4], dim=1)\n",
    "        dec3 = nn.ReLU()(self.dec_conv5(dec3))\n",
    "        dec3 = nn.ReLU()(self.dec_conv6(dec3))\n",
    "\n",
    "        dec4 = self.dec_upsample4(dec3)\n",
    "        dec4 = torch.cat([dec4, enc2], dim=1)\n",
    "        dec4 = nn.ReLU()(self.dec_conv7(dec4))\n",
    "        dec4 = nn.ReLU()(self.dec_conv8(dec4))\n",
    "\n",
    "        # Output\n",
    "        output = self.output_conv(dec4)\n",
    "        return output   \n",
    "    \n",
    "    # Create an instance of the FCN model\n",
    "model = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criterion and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, the CustomDataset takes in two lists of file paths: image_list and mask_list, representing the paths to the images and their corresponding masks, \n",
    "# respectively. It also takes in an optional transform argument to apply any necessary transformations to the images and masks.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, mask_list, transform=None, transform_mask=None):\n",
    "        self.image_list = [os.path.join(image_list, f) for f in os.listdir(image_list)]\n",
    "        self.mask_list = [os.path.join(mask_list, f) for f in os.listdir(mask_list)]\n",
    "        self.transform = transform\n",
    "        self.transform_mask = transform_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_list[idx]\n",
    "        mask_path = self.mask_list[idx]\n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert('RGB')\n",
    "        mask = Image.open(mask_path)\n",
    "        mask = mask.convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.transform_mask:\n",
    "            mask = self.transform_mask(mask)\n",
    "\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_real = 'yourPathToImages'\n",
    "folder_mask = 'yourPathToMasks'\n",
    "\n",
    "data = CustomDataset(folder_real,folder_mask, transform=transform, transform_mask=transform_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data loader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "len_train = len(train_loader)*batch_size\n",
    "len_val = len(val_loader)*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and STD calculations for real images\n",
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# Data normalization only based on training set\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    psum    += images.sum(axis        = [0, 2, 3])\n",
    "    psum_sq += (images ** 2).sum(axis = [0, 2, 3])\n",
    "    \n",
    "\n",
    "# Final Calculation\n",
    "# Resolution of the image\n",
    "image_size = 256\n",
    "count = len_train * image_size * image_size\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# output\n",
    "print('mean: '  + str(total_mean))\n",
    "print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the trasforms based on the computed mean and std\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=total_mean,\n",
    "                            std=total_std)\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data, now with normalization based on the training data\n",
    "data = CustomDataset(folder_real,folder_mask, transform=transform, transform_mask=transform_mask)\n",
    "\n",
    "# By using random seed 42 for both data splitting, it will result in the same split everytime.\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over the training data\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()*images.size(0)\n",
    "        # Print the loss every batch\n",
    "        if i % 1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Compute the validation loss\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            valid_loss += loss.item()*images.size(0)\n",
    "            # Accumulate the loss over all batches\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "    # Compute the average validation loss\n",
    "    val_loss /= len(val_data)\n",
    "    # Calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(val_loader.dataset)\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] , Val Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data in .csv file\n",
    "raw_data = {'Train_loss': train_loss_list,\n",
    "            'Valid_Loss': valid_loss_list}\n",
    "\n",
    "df = pd.DataFrame(raw_data, columns = ['Train_loss', 'Valid_Loss'])\n",
    "\n",
    "# Always check/change name for new model\n",
    "df.to_csv('pathToSaveCSV', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottig Train and Val Loss\n",
    "plt.plot(train_loss_list,  marker='o', label=\"Training Loss\")\n",
    "plt.plot(valid_loss_list,  marker='o', label=\"Validation Loss\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Loss curve realistic data (nameOfDataset)')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'pathToSaveWeightsFile.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = UNet()\n",
    "model.load_state_dict(torch.load('pathToSaveWeightsFile.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code shows an example of the generated mask based on the loaded model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# Load random sample from test_data to check mask visually\n",
    "img, label = test_data[random.randint(0, len(test_data)-1)]\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "# Assuming you have the trained model and a test image\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform forward pass on the test image\n",
    "with torch.no_grad():\n",
    "    output = model(img)  # Assuming you have the test image as a tensor\n",
    "# Convert the output tensor to a numpy array and squeeze the batch and channel dimensions\n",
    "output_np = output.squeeze(0).squeeze(0).cpu().numpy()\n",
    "# Apply a threshold to convert the output to a binary mask\n",
    "threshold_value =  threshold_otsu(output_np)\n",
    "mask = (output_np >= threshold_value).astype(np.float32)\n",
    "\n",
    "# Invert the origial transform of the loaded tesor\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = 1/total_std),\n",
    "                                transforms.Normalize(mean = -total_mean,\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "inv_tensor = invTrans(img)\n",
    "\n",
    "# Compute right order of tensor for plots\n",
    "img = inv_tensor.permute(0, 2, 3, 1)\n",
    "label = label.permute(1, 2, 0)\n",
    "\n",
    "# Reshape the tensor\n",
    "img = img.reshape(256, 256, 3)\n",
    "label = label.reshape(256, 256, 1)\n",
    "\n",
    "# Plot the original test image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the original mask\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(label)\n",
    "plt.title('Original Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the generated mask\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(mask)\n",
    "plt.title('Generated Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
